## Monitoramento

O monitoramento de caixa preta faz a testagem do comportamento externo do sistema, assim como o usuário vê. É um método baseado em amostragem, em que se monitora o mesmo sistema que é responsável pelas solicitações dos clientes. Esse monitoramento representa problemas ativos, não previstos, é feito de forma programável e contém um mecanismo de validação. Cada vez que uma sondagem é feita, são armazenados os resultados (aprovado ou com falhas) em relatórios e alertas. Assim, é possível que se faça o diagnóstico de um problema.  
O monitoramento caixa branca é capaz de inspecionar todos os processos internos do sistema, como logs (processos de registros de eventos) ou _endpoints_ _HTTP_ (ponto de extremidade conectado diretamente à rede principal), com instrumentação. Esse monitoramento, portanto, permite a detecção de problemas iminentes, falhas mascaradas por novas tentativas, e assim por diante.

As ***métricas de monitoramento*** variam de acordo com a necessidade particular de cada organização. No geral, mede-se:  
- **Latência**: tempo de execução, espera e resposta de atendimento de uma solicitação.  
- **Tráfego**: medida da carga de trabalho, da demanda que se exige do sistema. Qual é a média de solicitações, tempo e demanda da CPU.  
- **Erros**: mensura as taxas de solicitações com falhas, sejam parciais ou completas.  
- **Saturação**: controle dos recursos que precisam ser mais restritos (controle de memória ou restrição de E/S, por exemplo), medição de carga de trabalho em níveis mais altos (o sistema suporta um tráfego maior?) ou, ainda, identificar a capacidade de armazenamento de um disco.   
- **Disponibilidade de servidores:** quantificar quantos servidores estão ativos ou inativos em uma rede.  
- **Métricas de segurança**: definição dos computadores que estão com softwares antivírus instalados, _patches_ de segurança ativos, checar as intrusões, autenticações e autorizações, entre outras.

Geralmente, ==quando se constrói um sistema de monitoramento do zero, atribui-se a média de latência e o uso médio da CPU, da memória, da capacidade do banco de dados, etc==. São fatores que devem ser prioridades no planejamento das métricas. Com o emprego das métricas, será possível uma otimização que possibilitará que se faça um monitoramento contínuo em vários aspectos. É preciso que sejam feitas configurações, para que o monitoramento seja eficiente. Essas configurações incluem:  
- Fazer alterações no monitoramento da configuração (quantas solicitações de _pull request_ ou alterações por semana são feitas no repositório que contém a configuração de monitoramento?).  
- Ter controle dos falsos positivos (alertas que foram dados, mas que não ajudaram a prever falhas e precisam ser excluídos) e dos falsos negativos (falhas que aconteceram, mas que não foram alertadas).  
- Criar, confirmar e silenciar alertas.  
- Configurar a usabilidade dos alertas, _runbooks_ e painéis, para que seja compreensível por todos da equipe (GOOGLE CLOUD, 2021).

### Ferramentas de configurações para monitoramentos de SO e servidores  

Existem várias ferramentas de monitoramento no mercado. Essas ferramentas são responsáveis por analisar a funcionalidade de um sistema, gerar relatórios, apresentar alertas, ou seja, identificar problemas. Algumas têm, também, o caráter de monitoramento técnico, que se preocupa com a integridade do hardware ou dos sistemas. Algumas das ferramentas mais populares são: Remote network monitoring MIB (Rmon), OpenNMS, Cacti, Nagios, Tripwire e Zabbix.
Com a cultura DevOps, a utilização de uma ferramenta como o Zabbix e outras aqui citadas pode parecer desnecessária, no entanto o Zabbix traz, em sua proposta, uma ferramenta centralizada. Ao invés de trabalhar com várias ferramentas, o ideal é integrar todas elas e fazer com que todos os alertas sejam disparados por uma única.

>Na prática, os produtos são capazes de simplificar o monitoramento de eventos, mandando alertas somente do que realmente importa; detectam e respondem anomalias e atividades suspeitas; têm um pacote de segurança para ameaças internas; auditoria de usuários; autenticação; detecção de DoS; detecção de violação e de intrusão; filtram os dados relevantes; apresentam uma visibilidade completa dos ativos da rede; gerenciam as alterações e os _logs_ de eventos; detectam os desvios na linha de base segura; entre outras vantagens

### Monitoramento com foco nas práticas contemporâneas

- Prometheus: é uma ferramenta de monitoramento que, como as demais, agrega métricas, avalia expressões, mostra os resultados e gerencia alertas. Sua vantagem sobre as outras é que se trata de um sistema adaptável tanto para monitoração de arquiteturas centralizadas como para arquiteturas orientadas a serviços altamente dinâmicos.   
- Graphite: monitora tanto infraestruturas simples como em nuvens, assim como o desempenho de sites, aplicativos, serviços de negócios e servidores em rede. Com seu uso, tornou-se fácil armazenar, recuperar, compartilhar e visualizar dados de séries temporais.  
	- Comparado ao Prometheus, o Graphite é uma ferramenta com tarefas mais simples. Não coleta dados, seu modelo de dados é menos detalhado, os dados armazenados não podem ser configurados com o tempo que persistirão no disco e não suporta gerenciamento de alertas (BERMAN, 2020).  
- InfluxDB: executa análises para obter detecções e resoluções mais rápidas; configura alertas ou detecções de anomalias; faz ingestão de métricas, eventos e logs em um banco de dados de série temporal de alto desempenho; projetado para lidar com grandes volumes e várias fontes de dados.  
- Elastic Stack: o acrônico ELK surgiu como um projeto OpenSource que reunia três ferramentas: Elasticksearch, Logstash e Kibana. Com o aumento desses projetos, uma nova ferramenta foi inserida, a Beats, o que fez com que surgisse a ferramenta Elastic Stack e os projetos ficassem independentes. Assim, o Elastic Stack se tornou uma solução de monitoramento de aplicação, infraestrutura, análise de logs e segurança integrada, avançada e cheia de possiblidades   
- Logstash: é um pipeline que, de forma dinâmica, faz ingestão, transformação e envio de dados.   
- Kibana: é um visualizador de dados do Elasticksearch e do Elastic Stack. Com ele, você pode criar visualizações interativas, simples e intuitivas e criar dashboards com gráficos, mapas e filtros.  
- Fluentd: é um coletor de dados, também de código aberto, que possibilita a unificação da coleta e do consumo dos dados, melhorando o uso e a compreensão desses dados.   
- Grafana: é uma das ferramentas mais simples para observar métricas (Prometheus e Grafite), _logs_ e _traces_. Com o uso de agentes e integrações, ele monitora o sistema, define regras para alertas e notificações, agenda silêncios, entre outras funções.  
- FogMon: é uma ferramenta leve para monitoramento distribuído. Criada para ser executada em infraestruturas heterogêneas entre _cloud_ e _edge_, no entanto Correia (2019), em estudo de caso, constatou que as soluções que tiram proveito apenas da _cloud_ dispõem de recursos ilimitados, contudo apresentam resultados de latência elevada e congestão na rede. E as soluções orientadas apenas para a perspectiva da _edge_ podem não satisfazer os requisitos da aplicação, dada a instabilidade que apresentam em termos de recursos e falhas. A _FogMon_ foi escrita em C++ e tem uma arquitetura de duas camadas _peer-to-peer_. Opera com dois agentes de software: _followers_ ou _leaders_. Os _leaders_ monitoram os nós e agregam periodicamente os dados que os _followers_ recolhem.   
- _FMonE_: criada com foco em infraestruturas fog, ou seja, o processamento acontece no hub de dados ou em um roteador ou gateway, reduzindo a quantidade de dados enviados para a nuvem. Essa ferramenta contempla as principais características de sistemas com essa infraestrutura, que são: heterogeneidade, mobilidade, conectividade e distribuição geográfica, apresentando requisitos fundamentais, como: não necessidade de instalações, agregação e filtragem de métricas, _back-end_ flexível, elasticidade, resiliência, atenção nas localizações, monitoração de _plugins_, agnóstico no hardware e sistema operativo (CORREIA, 2019).  

E não esgotamos aqui as ferramentas de monitoramento, podemos citar Data Dog, New Relic, Elastic APM, Dinatrace, Graylog, Sentry, Alertmanager, Pagerduty e muitas outras amplamente trabalhadas no mundo DevOps. Existem ferramentas para cada realidade de monitoramento e de infraestrutura.  

As métricas e ferramentas de monitoração diferirão de acordo com a necessidade de cada empresa (cliente), mas, com a dinâmica e a importância dos computadores nos negócios de qualquer empresa, é imprescindível que se utilize da monitoração, seja para controle de infraestrutura, de aplicações ou até de negócios. Com o monitoramento, os mecanismos de notificações e os alertas, é possível perceber tudo o que está acontecendo na rede. Assim, é plausível projetar sistemas que fiquem disponíveis 24 horas, tomar decisões quando houver necessidade de aumento de escala, fazer backups seguros, monitorar unidades remotas e ambientes de virtualização, garantir a segurança dos seus ativos, usar dashboards para visualizar dados de forma mais eficiente e se adequar de forma flexível às mudanças, sempre presentes, nos processos tecnológicos.  

